{
  
    
        "post0": {
            "title": "Using Keras Tuner for hyperparameter tunning",
            "content": "Download and prepare the dataset . Kaggle competition: Tabular Playground Series - Aug 2021 -https://www.kaggle.com/c/tabular-playground-series-aug-2021 . Dataset: The dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with calculating the loss associated with a loan defaults. Although the features are anonymized, they have properties relating to real-world features. . Target: loss column . Notebook The code of this notebook is inspired by the lab Intro to Keras Tuner from Robert Crowe used on Course Machine Learning Modeling Pipelines in Production by DeepLearning.AI . from tensorflow import keras from tensorflow.keras import layers import numpy as np import tensorflow as tf from sklearn.model_selection import train_test_split . import os #for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for dirname, _, filenames in os.walk(&#39;./input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) . import pandas as pd from sklearn.model_selection import train_test_split # Read the data #X = pd.read_csv(&#39;../input/tabular-playground-series-aug-2021/train.csv&#39;, index_col=&#39;id&#39;) #X_test_full = pd.read_csv(&#39;../input/tabular-playground-series-aug-2021/test.csv&#39;, index_col=&#39;id&#39;) Xx = pd.read_csv(&#39;./input/train.csv&#39;, index_col=&#39;id&#39;) X_test = pd.read_csv(&#39;./input/test.csv&#39;, index_col=&#39;id&#39;) . X = Xx.copy(deep=True) X.dropna(axis=0, subset=[&#39;loss&#39;], inplace=True) Y = X.loss X.drop([&#39;loss&#39;], axis=1, inplace=True) . X.describe(include=&#39;all&#39;).transpose() . from sklearn.preprocessing import StandardScaler scaler = StandardScaler() X_scaled = scaler.fit_transform(X) X_test_index = X_test.index X_test_scaled = scaler.transform(X_test) . X_train, X_valid, Y_train, Y_valid = train_test_split(X_scaled, Y, train_size=0.8, test_size = 0.2,stratify=Y, random_state = 123) . print(X_train.shape) print(Y_train.shape) print(X_valid.shape) print(Y_valid.shape) print(X_test.shape) . Building DNN Model . DESIRED_MAE = 5 class myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs={}): if(logs.get(&#39;mean_absolute_error&#39;) &lt; DESIRED_MAE): print(&quot; nReached {}% MAE so cancelling training!&quot;.format(DESIRED_MAE)) self.model.stop_training = True . NUM_EPOCHS = 5 . inputs = keras.Input(shape=(X_train.shape[1])) model_dnn = tf.keras.models.Sequential([ tf.keras.layers.Dense(512,activation=&#39;relu&#39;,name=&#39;dense_1&#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10,activation=&#39;relu&#39;,name=&#39;dense_2&#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(1,activation=&#39;relu&#39;,name=&#39;dense_3&#39;) ]) model_dnn.compile(loss=&quot;mean_absolute_error&quot;, optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[&quot;mean_absolute_error&quot;]) #model_dnn.summary() history = model_dnn.fit(X_train, Y_train,epochs=NUM_EPOCHS, callbacks=[myCallback()]) . model_dnn.summary() . b_eval_dict = model_dnn.evaluate(X_valid, Y_valid, return_dict=True) . Let&#39;s define a helper function for displaying the results so it&#39;s easier to compare later. . def print_results(model, model_name, eval_dict): &#39;&#39;&#39; Prints the values of the hyparameters to tune, and the results of model evaluation Args: model (Model) - Keras model to evaluate model_name (string) - arbitrary string to be used in identifying the model eval_dict (dict) - results of model.evaluate &#39;&#39;&#39; print(f&#39; n{model_name}:&#39;) print(f&#39;number of units in 1st Dense layer: {model.get_layer(&quot;dense_1&quot;).units}&#39;) print(f&#39;learning rate for the optimizer: {model.optimizer.lr.numpy()}&#39;) for key,value in eval_dict.items(): print(f&#39;{key}: {value}&#39;) # Print results for baseline model print_results(model_dnn, &#39;BASELINE MODEL&#39;, b_eval_dict) . That&#39;s it for getting the results for a single set of hyperparameters. Let´s use Keras Tuner by having an API to automatically search for the optimal hyperparameters set. . Keras Tuner . To perform hypertuning with Keras Tuner, you will need to: . Define the model | Select which hyperparameters to tune | Define its search space | Define the search strategy | . Install and import packages . You will start by installing and importing the required packages. . !pip install -q -U keras-tuner . import tensorflow as tf import kerastuner as kt . Define the model . The model you set up for hypertuning is called a hypermodel. When you build this model, you define the hyperparameter search space in addition to the model architecture. . You can define a hypermodel through two approaches: . By using a model builder function | By subclassing the HyperModel class of the Keras Tuner API | . In this lab, you will take the first approach: you will use a model builder function to define the image classification model. This function returns a compiled model and uses hyperparameters you define inline to hypertune the model. . The function below basically builds the same model you used earlier. The difference is there are two hyperparameters that are setup for tuning: . the number of hidden units of the first Dense layer | the learning rate of the Adam optimizer | . You will see that this is done with a HyperParameters object which configures the hyperparameter you&#39;d like to tune. For this exercise, you will: . use its Int() method to define the search space for the Dense units. This allows you to set a minimum and maximum value, as well as the step size when incrementing between these values. . | use its Choice() method for the learning rate. This allows you to define discrete values to include in the search space when hypertuning. . | . You can view all available methods and its sample usage in the official documentation. . def model_builder(hp): &#39;&#39;&#39; Builds the model and sets up the hyperparameters to tune. Args: hp - Keras tuner object Returns: model with hyperparameters to tune &#39;&#39;&#39; # Initialize the Sequential API and start stacking the layers model = keras.Sequential() #model.add(keras.layers.Flatten(input_shape=(28, 28))) # Tune the number of units in the first Dense layer # Choose an optimal value between 32-512 hp_units = hp.Int(&#39;units&#39;, min_value=32, max_value=512, step=32) model.add(keras.layers.Dense(units=hp_units, activation=&#39;relu&#39;, name=&#39;dense_1&#39;)) # Add next layers model.add(keras.layers.Dropout(0.2)) model.add(tf.keras.layers.Dense(10,activation=&#39;relu&#39;,name=&#39;dense_2&#39;)) model.add(keras.layers.Dropout(0.2)) model.add(tf.keras.layers.Dense(1,activation=&#39;relu&#39;,name=&#39;dense_3&#39;)) # Tune the learning rate for the optimizer # Choose an optimal value from 0.01, 0.001, or 0.0001 hp_learning_rate = hp.Choice(&#39;learning_rate&#39;, values=[1e-2, 1e-3, 1e-4]) model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss=&quot;mean_absolute_error&quot;, metrics=[&#39;mean_absolute_error&#39;]) return model . Instantiate the Tuner and perform hypertuning . Now that you have the model builder, you can then define how the tuner can find the optimal set of hyperparameters, also called the search strategy. Keras Tuner has four tuners available with built-in strategies - RandomSearch, Hyperband, BayesianOptimization, and Sklearn. . In this tutorial, you will use the Hyperband tuner. Hyperband is an algorithm specifically developed for hyperparameter optimization. It uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket wherein the algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. You can read about the intuition behind the algorithm in section 3 of this paper. . Hyperband determines the number of models to train in a bracket by computing 1 + log`factor`(max_epochs) and rounding it up to the nearest integer. You will see these parameters (i.e. factor and max_epochs passed into the initializer below). In addition, you will also need to define the following to instantiate the Hyperband tuner: . the hypermodel (built by your model builder function) | the objective to optimize (e.g. validation accuracy) | a directory to save logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional overwrite=True argument while instantiating the tuner. | the project_name to differentiate with other runs. This will be used as a subdirectory name under the directory. | . You can refer to the documentation for other arguments you can pass in. . tuner = kt.Hyperband(model_builder, objective=&#39;val_mean_absolute_error&#39;, max_epochs=5, factor=3, directory=&#39;kt_dir&#39;, project_name=&#39;kt_hyperband&#39;) . Let&#39;s see a summary of the hyperparameters that you will tune: . tuner.search_space_summary() . You can pass in a callback to stop training early when a metric is not improving. Below, we define an EarlyStopping callback to monitor the validation loss and stop training if it&#39;s not improving after 5 epochs. . stop_early = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_mean_absolute_error&#39;, patience=5) . You will now run the hyperparameter search. The arguments for the search method are the same as those used for tf.keras.model.fit in addition to the callback above. This will take around 10 minutes to run. . tuner.search(X_train, Y_train, epochs=NUM_EPOCHS, validation_split=0.2, callbacks=[stop_early]) . You can get the top performing model with the get_best_hyperparameters() method. . best_hps=tuner.get_best_hyperparameters()[0] print(f&quot;&quot;&quot; The hyperparameter search is complete. The optimal number of units in the first densely-connected layer is {best_hps.get(&#39;units&#39;)} and the optimal learning rate for the optimizer is {best_hps.get(&#39;learning_rate&#39;)}. &quot;&quot;&quot;) . Build and train the model . Now that you have the best set of hyperparameters, you can rebuild the hypermodel with these values and retrain it. . h_model = tuner.hypermodel.build(best_hps) #h_model.summary() . h_model.fit(X_train, Y_train, epochs=NUM_EPOCHS, validation_split=0.2) . You will then get its performance against the test set. . h_eval_dict = h_model.evaluate(X_valid, Y_valid, return_dict=True) . We can compare the results we got with the baseline model we used at the start of the notebook. Results may vary but you will usually get a model that has less units in the dense layer, while having comparable loss and accuracy. This indicates that you reduced the model size and saved compute resources while still having more or less the same accuracy. . #print_results(b_model, &#39;BASELINE MODEL&#39;, b_eval_dict) print_results(h_model, &#39;HYPERTUNED MODEL&#39;, h_eval_dict) . Possible Improvements . If you want to keep practicing with Keras Tuner in this notebook, you can do a factory reset (Runtime &gt; Factory reset runtime) and take on any of the following: . hypertune the dropout layer with hp.Float() or hp.Choice() | hypertune the activation function of the 1st dense layer with hp.Choice() | determine the optimal number of Dense layers you can add to improve the model. You can use the code here as reference. | explore pre-defined HyperModel classes - HyperXception and HyperResNet for computer vision applications. | . Wrap Up . In this tutorial, you used Keras Tuner to conveniently tune hyperparameters. You defined which ones to tune, the search space, and search strategy to arrive at the optimal set of hyperparameters. These concepts will again be discussed in the next sections but in the context of AutoML, a package that automates the entire machine learning pipeline. On to the next! .",
            "url": "https://marcelcastrobr.github.io/notebooks/kerastuner/tensorflow/2021/09/05/KerasTuner.html",
            "relUrl": "/kerastuner/tensorflow/2021/09/05/KerasTuner.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Feature Engineering with Tensorflow",
            "content": "Week 1 Assignment: Data Validation . Tensorflow Data Validation (TFDV) is an open-source library that helps to understand, validate, and monitor production machine learning (ML) data at scale. Common use-cases include comparing training, evaluation and serving datasets, as well as checking for training/serving skew. You have seen the core functionalities of this package in the previous ungraded lab and you will get to practice them in this week&#39;s assignment. . In this lab, you will use TFDV in order to: . Generate and visualize statistics from a dataframe | Infer a dataset schema | Calculate, visualize and fix anomalies | . Let&#39;s begin! . . 1 - Setup and Imports . import os import pandas as pd import tensorflow as tf import tempfile, urllib, zipfile import tensorflow_data_validation as tfdv from tensorflow.python.lib.io import file_io from tensorflow_data_validation.utils import slicing_util from tensorflow_metadata.proto.v0.statistics_pb2 import DatasetFeatureStatisticsList, DatasetFeatureStatistics # Set TF&#39;s logger to only display errors to avoid internal warnings being shown tf.get_logger().setLevel(&#39;ERROR&#39;) . . 2 - Load the Dataset . You will be using the Diabetes 130-US hospitals for years 1999-2008 Data Set donated to the University of California, Irvine (UCI) Machine Learning Repository. The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. . This dataset has already been included in your Jupyter workspace so you can easily load it. . . 2.1 Read and Split the Dataset . df = pd.read_csv(&#39;dataset_diabetes/diabetic_data.csv&#39;, header=0, na_values = &#39;?&#39;) # Preview the dataset df.head() . encounter_id patient_nbr race gender age weight admission_type_id discharge_disposition_id admission_source_id time_in_hospital ... citoglipton insulin glyburide-metformin glipizide-metformin glimepiride-pioglitazone metformin-rosiglitazone metformin-pioglitazone change diabetesMed readmitted . 0 2278392 | 8222157 | Caucasian | Female | [0-10) | NaN | 6 | 25 | 1 | 1 | ... | No | No | No | No | No | No | No | No | No | NO | . 1 149190 | 55629189 | Caucasian | Female | [10-20) | NaN | 1 | 1 | 7 | 3 | ... | No | Up | No | No | No | No | No | Ch | Yes | &gt;30 | . 2 64410 | 86047875 | AfricanAmerican | Female | [20-30) | NaN | 1 | 1 | 7 | 2 | ... | No | No | No | No | No | No | No | No | Yes | NO | . 3 500364 | 82442376 | Caucasian | Male | [30-40) | NaN | 1 | 1 | 7 | 2 | ... | No | Up | No | No | No | No | No | Ch | Yes | NO | . 4 16680 | 42519267 | Caucasian | Male | [40-50) | NaN | 1 | 1 | 7 | 1 | ... | No | Steady | No | No | No | No | No | Ch | Yes | NO | . 5 rows × 50 columns . . Data splits . In a production ML system, the model performance can be negatively affected by anomalies and divergence between data splits for training, evaluation, and serving. To emulate a production system, you will split the dataset into: . 70% training set | 15% evaluation set | 15% serving set | . You will then use TFDV to visualize, analyze, and understand the data. You will create a data schema from the training dataset, then compare the evaluation and serving sets with this schema to detect anomalies and data drift/skew. . . Label Column . This dataset has been prepared to analyze the factors related to readmission outcome. In this notebook, you will treat the readmitted column as the target or label column. . The target (or label) is important to know while splitting the data into training, evaluation and serving sets. In supervised learning, you need to include the target in the training and evaluation datasets. For the serving set however (i.e. the set that simulates the data coming from your users), the label column needs to be dropped since that is the feature that your model will be trying to predict. . The following function returns the training, evaluation and serving partitions of a given dataset: . def prepare_data_splits_from_dataframe(df): &#39;&#39;&#39; Splits a Pandas Dataframe into training, evaluation and serving sets. Parameters: df : pandas dataframe to split Returns: train_df: Training dataframe(70% of the entire dataset) eval_df: Evaluation dataframe (15% of the entire dataset) serving_df: Serving dataframe (15% of the entire dataset, label column dropped) &#39;&#39;&#39; # 70% of records for generating the training set train_len = int(len(df) * 0.7) # Remaining 30% of records for generating the evaluation and serving sets eval_serv_len = len(df) - train_len # Half of the 30%, which makes up 15% of total records, for generating the evaluation set eval_len = eval_serv_len // 2 # Remaining 15% of total records for generating the serving set serv_len = eval_serv_len - eval_len # Sample the train, validation and serving sets. We specify a random state for repeatable outcomes. train_df = df.iloc[:train_len].sample(frac=1, random_state=48).reset_index(drop=True) eval_df = df.iloc[train_len: train_len + eval_len].sample(frac=1, random_state=48).reset_index(drop=True) serving_df = df.iloc[train_len + eval_len: train_len + eval_len + serv_len].sample(frac=1, random_state=48).reset_index(drop=True) # Serving data emulates the data that would be submitted for predictions, so it should not have the label column. serving_df = serving_df.drop([&#39;readmitted&#39;], axis=1) return train_df, eval_df, serving_df . train_df, eval_df, serving_df = prepare_data_splits_from_dataframe(df) print(&#39;Training dataset has {} records nValidation dataset has {} records nServing dataset has {} records&#39;.format(len(train_df),len(eval_df),len(serving_df))) . Training dataset has 71236 records Validation dataset has 15265 records Serving dataset has 15265 records . . 3 - Generate and Visualize Training Data Statistics . In this section, you will be generating descriptive statistics from the dataset. This is usually the first step when dealing with a dataset you are not yet familiar with. It is also known as performing an exploratory data analysis and its purpose is to understand the data types, the data itself and any possible issues that need to be addressed. . It is important to mention that exploratory data analysis should be perfomed on the training dataset only. This is because getting information out of the evaluation or serving datasets can be seen as &quot;cheating&quot; since this data is used to emulate data that you have not collected yet and will try to predict using your ML algorithm. In general, it is a good practice to avoid leaking information from your evaluation and serving data into your model. . . Removing Irrelevant Features . Before you generate the statistics, you may want to drop irrelevant features from your dataset. You can do that with TFDV with the tfdv.StatsOptions class. It is usually not a good idea to drop features without knowing what information they contain. However there are times when this can be fairly obvious. . One of the important parameters of the StatsOptions class is feature_whitelist, which defines the features to include while calculating the data statistics. You can check the documentation to learn more about the class arguments. . In this case, you will omit the statistics for encounter_id and patient_nbr since they are part of the internal tracking of patients in the hospital and they don&#39;t contain valuable information for the task at hand. . features_to_remove = {&#39;encounter_id&#39;, &#39;patient_nbr&#39;} # Collect features to whitelist while computing the statistics approved_cols = [col for col in df.columns if (col not in features_to_remove)] # Instantiate a StatsOptions class and define the feature_whitelist property stats_options = tfdv.StatsOptions(feature_whitelist=approved_cols) # Review the features to generate the statistics print(stats_options.feature_whitelist) . [&#39;race&#39;, &#39;gender&#39;, &#39;age&#39;, &#39;weight&#39;, &#39;admission_type_id&#39;, &#39;discharge_disposition_id&#39;, &#39;admission_source_id&#39;, &#39;time_in_hospital&#39;, &#39;payer_code&#39;, &#39;medical_specialty&#39;, &#39;num_lab_procedures&#39;, &#39;num_procedures&#39;, &#39;num_medications&#39;, &#39;number_outpatient&#39;, &#39;number_emergency&#39;, &#39;number_inpatient&#39;, &#39;diag_1&#39;, &#39;diag_2&#39;, &#39;diag_3&#39;, &#39;number_diagnoses&#39;, &#39;max_glu_serum&#39;, &#39;A1Cresult&#39;, &#39;metformin&#39;, &#39;repaglinide&#39;, &#39;nateglinide&#39;, &#39;chlorpropamide&#39;, &#39;glimepiride&#39;, &#39;acetohexamide&#39;, &#39;glipizide&#39;, &#39;glyburide&#39;, &#39;tolbutamide&#39;, &#39;pioglitazone&#39;, &#39;rosiglitazone&#39;, &#39;acarbose&#39;, &#39;miglitol&#39;, &#39;troglitazone&#39;, &#39;tolazamide&#39;, &#39;examide&#39;, &#39;citoglipton&#39;, &#39;insulin&#39;, &#39;glyburide-metformin&#39;, &#39;glipizide-metformin&#39;, &#39;glimepiride-pioglitazone&#39;, &#39;metformin-rosiglitazone&#39;, &#39;metformin-pioglitazone&#39;, &#39;change&#39;, &#39;diabetesMed&#39;, &#39;readmitted&#39;] . . Exercise 1: Generate Training Statistics . TFDV allows you to generate statistics from different data formats such as CSV or a Pandas DataFrame. . Since you already have the data stored in a DataFrame you can use the function tfdv.generate_statistics_from_dataframe() which, given a DataFrame and stats_options, generates an object of type DatasetFeatureStatisticsList. This object includes the computed statistics of the given dataset. . Complete the cell below to generate the statistics of the training set. Remember to pass the training dataframe and the stats_options that you defined above as arguments. . train_stats = tfdv.generate_statistics_from_dataframe(train_df, stats_options) ### END CODE HERE . # get the number of features used to compute statistics print(f&quot;Number of features used: {len(train_stats.datasets[0].features)}&quot;) # check the number of examples used print(f&quot;Number of examples used: {train_stats.datasets[0].num_examples}&quot;) # check the column names of the first and last feature print(f&quot;First feature: {train_stats.datasets[0].features[0].path.step[0]}&quot;) print(f&quot;Last feature: {train_stats.datasets[0].features[-1].path.step[0]}&quot;) . Number of features used: 48 Number of examples used: 71236 First feature: race Last feature: readmitted . Expected Output: . Number of features used: 48 Number of examples used: 71236 First feature: race Last feature: readmitted . . Exercise 2: Visualize Training Statistics . Now that you have the computed statistics in the DatasetFeatureStatisticsList instance, you will need a way to visualize these to get actual insights. TFDV provides this functionality through the method tfdv.visualize_statistics(). . Using this function in an interactive Python environment such as this one will output a very nice and convenient way to interact with the descriptive statistics you generated earlier. . Try it out yourself! Remember to pass in the generated training statistics in the previous exercise as an argument. . tfdv.visualize_statistics(train_stats) ### END CODE HERE . . 4 - Infer a data schema . A schema defines the properties of the data and can thus be used to detect errors. Some of these properties include: . which features are expected to be present | feature type | the number of values for a feature in each example | the presence of each feature across all examples | the expected domains of features | . The schema is expected to be fairly static, whereas statistics can vary per data split. So, you will infer the data schema from only the training dataset. Later, you will generate statistics for evaluation and serving datasets and compare their state with the data schema to detect anomalies, drift and skew. . . Exercise 3: Infer the training set schema . Schema inference is straightforward using tfdv.infer_schema(). This function needs only the statistics (an instance of DatasetFeatureStatisticsList) of your data as input. The output will be a Schema protocol buffer containing the results. . A complimentary function is tfdv.display_schema() for displaying the schema in a table. This accepts a Schema protocol buffer as input. . Fill the code below to infer the schema from the training statistics using TFDV and display the result. . # Infer the data schema by using the training statistics that you generated schema = tfdv.infer_schema(statistics=train_stats) # Display the data schema tfdv.display_schema(schema) ### END CODE HERE . Type Presence Valency Domain . Feature name . &#39;race&#39; STRING | optional | single | &#39;race&#39; | . &#39;gender&#39; STRING | required | | &#39;gender&#39; | . &#39;age&#39; STRING | required | | &#39;age&#39; | . &#39;weight&#39; STRING | optional | single | &#39;weight&#39; | . &#39;admission_type_id&#39; INT | required | | - | . &#39;discharge_disposition_id&#39; INT | required | | - | . &#39;admission_source_id&#39; INT | required | | - | . &#39;time_in_hospital&#39; INT | required | | - | . &#39;payer_code&#39; STRING | optional | single | &#39;payer_code&#39; | . &#39;medical_specialty&#39; STRING | optional | single | &#39;medical_specialty&#39; | . &#39;num_lab_procedures&#39; INT | required | | - | . &#39;num_procedures&#39; INT | required | | - | . &#39;num_medications&#39; INT | required | | - | . &#39;number_outpatient&#39; INT | required | | - | . &#39;number_emergency&#39; INT | required | | - | . &#39;number_inpatient&#39; INT | required | | - | . &#39;diag_1&#39; BYTES | optional | single | - | . &#39;diag_2&#39; BYTES | optional | single | - | . &#39;diag_3&#39; BYTES | optional | single | - | . &#39;number_diagnoses&#39; INT | required | | - | . &#39;max_glu_serum&#39; STRING | required | | &#39;max_glu_serum&#39; | . &#39;A1Cresult&#39; STRING | required | | &#39;A1Cresult&#39; | . &#39;metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;repaglinide&#39; STRING | required | | &#39;repaglinide&#39; | . &#39;nateglinide&#39; STRING | required | | &#39;nateglinide&#39; | . &#39;chlorpropamide&#39; STRING | required | | &#39;chlorpropamide&#39; | . &#39;glimepiride&#39; STRING | required | | &#39;glimepiride&#39; | . &#39;acetohexamide&#39; STRING | required | | &#39;acetohexamide&#39; | . &#39;glipizide&#39; STRING | required | | &#39;glipizide&#39; | . &#39;glyburide&#39; STRING | required | | &#39;glyburide&#39; | . &#39;tolbutamide&#39; STRING | required | | &#39;tolbutamide&#39; | . &#39;pioglitazone&#39; STRING | required | | &#39;pioglitazone&#39; | . &#39;rosiglitazone&#39; STRING | required | | &#39;rosiglitazone&#39; | . &#39;acarbose&#39; STRING | required | | &#39;acarbose&#39; | . &#39;miglitol&#39; STRING | required | | &#39;miglitol&#39; | . &#39;troglitazone&#39; STRING | required | | &#39;troglitazone&#39; | . &#39;tolazamide&#39; STRING | required | | &#39;tolazamide&#39; | . &#39;examide&#39; STRING | required | | &#39;examide&#39; | . &#39;citoglipton&#39; STRING | required | | &#39;citoglipton&#39; | . &#39;insulin&#39; STRING | required | | &#39;insulin&#39; | . &#39;glyburide-metformin&#39; STRING | required | | &#39;glyburide-metformin&#39; | . &#39;glipizide-metformin&#39; STRING | required | | &#39;glipizide-metformin&#39; | . &#39;glimepiride-pioglitazone&#39; STRING | required | | &#39;glimepiride-pioglitazone&#39; | . &#39;metformin-rosiglitazone&#39; STRING | required | | &#39;metformin-rosiglitazone&#39; | . &#39;metformin-pioglitazone&#39; STRING | required | | &#39;metformin-pioglitazone&#39; | . &#39;change&#39; STRING | required | | &#39;change&#39; | . &#39;diabetesMed&#39; STRING | required | | &#39;diabetesMed&#39; | . &#39;readmitted&#39; STRING | required | | &#39;readmitted&#39; | . Values . Domain . &#39;race&#39; &#39;AfricanAmerican&#39;, &#39;Asian&#39;, &#39;Caucasian&#39;, &#39;Hispanic&#39;, &#39;Other&#39; | . &#39;gender&#39; &#39;Female&#39;, &#39;Male&#39;, &#39;Unknown/Invalid&#39; | . &#39;age&#39; &#39;[0-10)&#39;, &#39;[10-20)&#39;, &#39;[20-30)&#39;, &#39;[30-40)&#39;, &#39;[40-50)&#39;, &#39;[50-60)&#39;, &#39;[60-70)&#39;, &#39;[70-80)&#39;, &#39;[80-90)&#39;, &#39;[90-100)&#39; | . &#39;weight&#39; &#39;&gt;200&#39;, &#39;[0-25)&#39;, &#39;[100-125)&#39;, &#39;[125-150)&#39;, &#39;[150-175)&#39;, &#39;[175-200)&#39;, &#39;[25-50)&#39;, &#39;[50-75)&#39;, &#39;[75-100)&#39; | . &#39;payer_code&#39; &#39;BC&#39;, &#39;CH&#39;, &#39;CM&#39;, &#39;CP&#39;, &#39;DM&#39;, &#39;HM&#39;, &#39;MC&#39;, &#39;MD&#39;, &#39;MP&#39;, &#39;OG&#39;, &#39;OT&#39;, &#39;PO&#39;, &#39;SI&#39;, &#39;SP&#39;, &#39;UN&#39;, &#39;WC&#39; | . &#39;medical_specialty&#39; &#39;AllergyandImmunology&#39;, &#39;Anesthesiology&#39;, &#39;Anesthesiology-Pediatric&#39;, &#39;Cardiology&#39;, &#39;Cardiology-Pediatric&#39;, &#39;Dentistry&#39;, &#39;Dermatology&#39;, &#39;Emergency/Trauma&#39;, &#39;Endocrinology&#39;, &#39;Family/GeneralPractice&#39;, &#39;Gastroenterology&#39;, &#39;Gynecology&#39;, &#39;Hematology&#39;, &#39;Hematology/Oncology&#39;, &#39;Hospitalist&#39;, &#39;InfectiousDiseases&#39;, &#39;InternalMedicine&#39;, &#39;Nephrology&#39;, &#39;Neurology&#39;, &#39;Obsterics&amp;Gynecology-GynecologicOnco&#39;, &#39;Obstetrics&#39;, &#39;ObstetricsandGynecology&#39;, &#39;Oncology&#39;, &#39;Ophthalmology&#39;, &#39;Orthopedics&#39;, &#39;Orthopedics-Reconstructive&#39;, &#39;Osteopath&#39;, &#39;Otolaryngology&#39;, &#39;OutreachServices&#39;, &#39;Pathology&#39;, &#39;Pediatrics&#39;, &#39;Pediatrics-AllergyandImmunology&#39;, &#39;Pediatrics-CriticalCare&#39;, &#39;Pediatrics-EmergencyMedicine&#39;, &#39;Pediatrics-Endocrinology&#39;, &#39;Pediatrics-Hematology-Oncology&#39;, &#39;Pediatrics-InfectiousDiseases&#39;, &#39;Pediatrics-Neurology&#39;, &#39;Pediatrics-Pulmonology&#39;, &#39;Perinatology&#39;, &#39;PhysicalMedicineandRehabilitation&#39;, &#39;PhysicianNotFound&#39;, &#39;Podiatry&#39;, &#39;Proctology&#39;, &#39;Psychiatry&#39;, &#39;Psychiatry-Addictive&#39;, &#39;Psychiatry-Child/Adolescent&#39;, &#39;Psychology&#39;, &#39;Pulmonology&#39;, &#39;Radiologist&#39;, &#39;Radiology&#39;, &#39;Rheumatology&#39;, &#39;Speech&#39;, &#39;SportsMedicine&#39;, &#39;Surgeon&#39;, &#39;Surgery-Cardiovascular&#39;, &#39;Surgery-Cardiovascular/Thoracic&#39;, &#39;Surgery-Colon&amp;Rectal&#39;, &#39;Surgery-General&#39;, &#39;Surgery-Maxillofacial&#39;, &#39;Surgery-Neuro&#39;, &#39;Surgery-Pediatric&#39;, &#39;Surgery-Plastic&#39;, &#39;Surgery-PlasticwithinHeadandNeck&#39;, &#39;Surgery-Thoracic&#39;, &#39;Surgery-Vascular&#39;, &#39;SurgicalSpecialty&#39;, &#39;Urology&#39; | . &#39;max_glu_serum&#39; &#39;&gt;200&#39;, &#39;&gt;300&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;A1Cresult&#39; &#39;&gt;7&#39;, &#39;&gt;8&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;repaglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;nateglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;chlorpropamide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glimepiride&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acetohexamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glipizide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;tolbutamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;pioglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;rosiglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acarbose&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;miglitol&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;troglitazone&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;tolazamide&#39; &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;examide&#39; &#39;No&#39; | . &#39;citoglipton&#39; &#39;No&#39; | . &#39;insulin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide-metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glipizide-metformin&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glimepiride-pioglitazone&#39; &#39;No&#39; | . &#39;metformin-rosiglitazone&#39; &#39;No&#39; | . &#39;metformin-pioglitazone&#39; &#39;No&#39; | . &#39;change&#39; &#39;Ch&#39;, &#39;No&#39; | . &#39;diabetesMed&#39; &#39;No&#39;, &#39;Yes&#39; | . &#39;readmitted&#39; &#39;&lt;30&#39;, &#39;&gt;30&#39;, &#39;NO&#39; | . # Check number of features print(f&quot;Number of features in schema: {len(schema.feature)}&quot;) # Check domain name of 2nd feature print(f&quot;Second feature in schema: {list(schema.feature)[1].domain}&quot;) . Number of features in schema: 48 Second feature in schema: gender . Expected Output: . Number of features in schema: 48 Second feature in schema: gender . Be sure to check the information displayed before moving forward. . . 5 - Calculate, Visualize and Fix Evaluation Anomalies . It is important that the schema of the evaluation data is consistent with the training data since the data that your model is going to receive should be consistent to the one you used to train it with. . Moreover, it is also important that the features of the evaluation data belong roughly to the same range as the training data. This ensures that the model will be evaluated on a similar loss surface covered during training. . . Exercise 4: Compare Training and Evaluation Statistics . Now you are going to generate the evaluation statistics and compare it with training statistics. You can use the tfdv.generate_statistics_from_dataframe() function for this. But this time, you&#39;ll need to pass the evaluation data. For the stats_options parameter, the list you used before works here too. . Remember that to visualize the evaluation statistics you can use tfdv.visualize_statistics(). . However, it is impractical to visualize both statistics separately and do your comparison from there. Fortunately, TFDV has got this covered. You can use the visualize_statistics function and pass additional parameters to overlay the statistics from both datasets (referenced as left-hand side and right-hand side statistics). Let&#39;s see what these parameters are: . lhs_statistics: Required parameter. Expects an instance of DatasetFeatureStatisticsList. | . rhs_statistics: Expects an instance of DatasetFeatureStatisticsList to compare with lhs_statistics. | . lhs_name: Name of the lhs_statistics dataset. | . rhs_name: Name of the rhs_statistics dataset. | . For this case, remember to define the lhs_statistics protocol with the eval_stats, and the optional rhs_statistics protocol with the train_stats. . Additionally, check the function for the protocol name declaration, and define the lhs and rhs names as &#39;EVAL_DATASET&#39; and &#39;TRAIN_DATASET&#39; respectively. . # Generate evaluation dataset statistics # HINT: Remember to use the evaluation dataframe and to pass the stats_options (that you defined before) as an argument eval_stats = tfdv.generate_statistics_from_dataframe(eval_df, stats_options) # Compare evaluation data with training data # HINT: Remember to use both the evaluation and training statistics with the lhs_statistics and rhs_statistics arguments # HINT: Assign the names of &#39;EVAL_DATASET&#39; and &#39;TRAIN_DATASET&#39; to the lhs and rhs protocols tfdv.visualize_statistics( lhs_statistics=eval_stats, rhs_statistics=train_stats, lhs_name=&#39;EVAL_DATASET&#39;, rhs_name=&#39;TRAIN_DATASET&#39; ) ### END CODE HERE . # get the number of features used to compute statistics print(f&quot;Number of features: {len(eval_stats.datasets[0].features)}&quot;) # check the number of examples used print(f&quot;Number of examples: {eval_stats.datasets[0].num_examples}&quot;) # check the column names of the first and last feature print(f&quot;First feature: {eval_stats.datasets[0].features[0].path.step[0]}&quot;) print(f&quot;Last feature: {eval_stats.datasets[0].features[-1].path.step[0]}&quot;) . Number of features: 48 Number of examples: 15265 First feature: race Last feature: readmitted . Expected Output: . Number of features: 48 Number of examples: 15265 First feature: race Last feature: readmitted . . Exercise 5: Detecting Anomalies . At this point, you should ask if your evaluation dataset matches the schema from your training dataset. For instance, if you scroll through the output cell in the previous exercise, you can see that the categorical feature glimepiride-pioglitazone has 1 unique value in the training set while the evaluation dataset has 2. You can verify with the built-in Pandas describe() method as well. . train_df[&quot;glimepiride-pioglitazone&quot;].describe() . count 71236 unique 1 top No freq 71236 Name: glimepiride-pioglitazone, dtype: object . eval_df[&quot;glimepiride-pioglitazone&quot;].describe() . count 15265 unique 2 top No freq 15264 Name: glimepiride-pioglitazone, dtype: object . It is possible but highly inefficient to visually inspect and determine all the anomalies. So, let&#39;s instead use TFDV functions to detect and display these. . You can use the function tfdv.validate_statistics() for detecting anomalies and tfdv.display_anomalies() for displaying them. . The validate_statistics() method has two required arguments: . an instance of DatasetFeatureStatisticsList | an instance of Schema | . Fill in the following graded function which, given the statistics and schema, displays the anomalies found. . def calculate_and_display_anomalies(statistics, schema): &#39;&#39;&#39; Calculate and display anomalies. Parameters: statistics : Data statistics in statistics_pb2.DatasetFeatureStatisticsList format schema : Data schema in schema_pb2.Schema format Returns: display of calculated anomalies &#39;&#39;&#39; ### START CODE HERE # HINTS: Pass the statistics and schema parameters into the validation function anomalies = tfdv.validate_statistics(statistics=statistics, schema=schema) # HINTS: Display input anomalies by using the calculated anomalies tfdv.display_anomalies(anomalies) ### END CODE HERE . You should see detected anomalies in the medical_specialty and glimepiride-pioglitazone features by running the cell below. . calculate_and_display_anomalies(eval_stats, schema=schema) . No anomalies found. . . Exercise 6: Fix evaluation anomalies in the schema . The evaluation data has records with values for the features glimepiride-pioglitazone and medical_speciality that were not included in the schema generated from the training data. You can fix this by adding the new values that exist in the evaluation dataset to the domain of these features. . To get the domain of a particular feature you can use tfdv.get_domain(). . You can use the append() method to the value property of the returned domain to add strings to the valid list of values. To be more explicit, given a domain you can do something like: . domain.value.append(&quot;feature_value&quot;) . # Get the domain associated with the input feature, glimepiride-pioglitazone, from the schema glimepiride_pioglitazone_domain = tfdv.get_domain(schema, &#39;glimepiride-pioglitazone&#39;) print(glimepiride_pioglitazone_domain) # HINT: Append the missing value &#39;Steady&#39; to the domain glimepiride_pioglitazone_domain.value.append(&#39;Steady&#39;) print(glimepiride_pioglitazone_domain) # Get the domain associated with the input feature, medical_specialty, from the schema medical_specialty_domain = tfdv.get_domain(schema, &#39;medical_specialty&#39;) print(type(medical_specialty_domain)) # HINT: Append the missing value &#39;Neurophysiology&#39; to the domain medical_specialty_domain.value.append(&#39;Neurophysiology&#39;) #print(medical_specialty_domain) # HINT: Re-calculate and re-display anomalies with the new schema calculate_and_display_anomalies(eval_stats, schema=schema) ### END CODE HERE . name: &#34;glimepiride-pioglitazone&#34; value: &#34;No&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; name: &#34;glimepiride-pioglitazone&#34; value: &#34;No&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; value: &#34;Steady&#34; &lt;class &#39;tensorflow_metadata.proto.v0.schema_pb2.StringDomain&#39;&gt; . No anomalies found. . If you did the exercise correctly, you should see &quot;No anomalies found.&quot; after running the cell above. . . 6 - Schema Environments . By default, all datasets in a pipeline should use the same schema. However, there are some exceptions. . For example, the label column is dropped in the serving set so this will be flagged when comparing with the training set schema. . In this case, introducing slight schema variations is necessary. . . Exercise 7: Check anomalies in the serving set . Now you are going to check for anomalies in the serving data. The process is very similar to the one you previously did for the evaluation data with a little change. . Let&#39;s create a new StatsOptions that is aware of the information provided by the schema and use it when generating statistics from the serving DataFrame. . options = tfdv.StatsOptions(schema=schema, infer_type_from_schema=True, feature_whitelist=approved_cols) . # Generate serving dataset statistics # HINT: Remember to use the serving dataframe and to pass the newly defined statistics options #serving_stats = tfdv.generate_statistics_from_dataframe(None, stats_options=None) serving_stats = tfdv.generate_statistics_from_dataframe(serving_df, stats_options=options) # HINT: Calculate and display anomalies using the generated serving statistics #calculate_and_display_anomalies(None, schema=None) calculate_and_display_anomalies(serving_stats, schema=schema) ### END CODE HERE . Anomaly short description Anomaly long description . Feature name . &#39;metformin-pioglitazone&#39; Unexpected string values | Examples contain values missing from the schema: Steady (&lt;1%). | . &#39;payer_code&#39; Unexpected string values | Examples contain values missing from the schema: FR (&lt;1%). | . &#39;medical_specialty&#39; Unexpected string values | Examples contain values missing from the schema: DCPTEAM (&lt;1%), Endocrinology-Metabolism (&lt;1%), Resident (&lt;1%). | . &#39;metformin-rosiglitazone&#39; Unexpected string values | Examples contain values missing from the schema: Steady (&lt;1%). | . &#39;readmitted&#39; Column dropped | Column is completely missing | . You should see that metformin-rosiglitazone, metformin-pioglitazone, payer_code and medical_specialty features have an anomaly (i.e. Unexpected string values) which is less than 1%. . Let&#39;s relax the anomaly detection constraints for the last two of these features by defining the min_domain_mass of the feature&#39;s distribution constraints. . # Get the feature and relax to match 90% of the domain payer_code = tfdv.get_feature(schema, &#39;payer_code&#39;) payer_code.distribution_constraints.min_domain_mass = 0.9 # Get the feature and relax to match 90% of the domain medical_specialty = tfdv.get_feature(schema, &#39;medical_specialty&#39;) medical_specialty.distribution_constraints.min_domain_mass = 0.9 # Detect anomalies with the updated constraints calculate_and_display_anomalies(serving_stats, schema=schema) . Anomaly short description Anomaly long description . Feature name . &#39;metformin-pioglitazone&#39; Unexpected string values | Examples contain values missing from the schema: Steady (&lt;1%). | . &#39;metformin-rosiglitazone&#39; Unexpected string values | Examples contain values missing from the schema: Steady (&lt;1%). | . &#39;readmitted&#39; Column dropped | Column is completely missing | . If the payer_code and medical_specialty are no longer part of the output cell, then the relaxation worked! . . Exercise 8: Modifying the Domain . Let&#39;s investigate the possible cause of the anomalies for the other features, namely metformin-pioglitazone and metformin-rosiglitazone. From the output of the previous exercise, you&#39;ll see that the anomaly long description says: &quot;Examples contain values missing from the schema: Steady (&lt;1%)&quot;. You can redisplay the schema and look at the domain of these features to verify this statement. . When you inferred the schema at the start of this lab, it&#39;s possible that some values were not detected in the training data so it was not included in the expected domain values of the feature&#39;s schema. In the case of metformin-rosiglitazone and metformin-pioglitazone, the value &quot;Steady&quot; is indeed missing. You will just see &quot;No&quot; in the domain of these two features after running the code cell below. . tfdv.display_schema(schema) . Type Presence Valency Domain . Feature name . &#39;race&#39; STRING | optional | single | &#39;race&#39; | . &#39;gender&#39; STRING | required | | &#39;gender&#39; | . &#39;age&#39; STRING | required | | &#39;age&#39; | . &#39;weight&#39; STRING | optional | single | &#39;weight&#39; | . &#39;admission_type_id&#39; INT | required | | - | . &#39;discharge_disposition_id&#39; INT | required | | - | . &#39;admission_source_id&#39; INT | required | | - | . &#39;time_in_hospital&#39; INT | required | | - | . &#39;payer_code&#39; STRING | optional | single | &#39;payer_code&#39; | . &#39;medical_specialty&#39; STRING | optional | single | &#39;medical_specialty&#39; | . &#39;num_lab_procedures&#39; INT | required | | - | . &#39;num_procedures&#39; INT | required | | - | . &#39;num_medications&#39; INT | required | | - | . &#39;number_outpatient&#39; INT | required | | - | . &#39;number_emergency&#39; INT | required | | - | . &#39;number_inpatient&#39; INT | required | | - | . &#39;diag_1&#39; BYTES | optional | single | - | . &#39;diag_2&#39; BYTES | optional | single | - | . &#39;diag_3&#39; BYTES | optional | single | - | . &#39;number_diagnoses&#39; INT | required | | - | . &#39;max_glu_serum&#39; STRING | required | | &#39;max_glu_serum&#39; | . &#39;A1Cresult&#39; STRING | required | | &#39;A1Cresult&#39; | . &#39;metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;repaglinide&#39; STRING | required | | &#39;repaglinide&#39; | . &#39;nateglinide&#39; STRING | required | | &#39;nateglinide&#39; | . &#39;chlorpropamide&#39; STRING | required | | &#39;chlorpropamide&#39; | . &#39;glimepiride&#39; STRING | required | | &#39;glimepiride&#39; | . &#39;acetohexamide&#39; STRING | required | | &#39;acetohexamide&#39; | . &#39;glipizide&#39; STRING | required | | &#39;glipizide&#39; | . &#39;glyburide&#39; STRING | required | | &#39;glyburide&#39; | . &#39;tolbutamide&#39; STRING | required | | &#39;tolbutamide&#39; | . &#39;pioglitazone&#39; STRING | required | | &#39;pioglitazone&#39; | . &#39;rosiglitazone&#39; STRING | required | | &#39;rosiglitazone&#39; | . &#39;acarbose&#39; STRING | required | | &#39;acarbose&#39; | . &#39;miglitol&#39; STRING | required | | &#39;miglitol&#39; | . &#39;troglitazone&#39; STRING | required | | &#39;troglitazone&#39; | . &#39;tolazamide&#39; STRING | required | | &#39;tolazamide&#39; | . &#39;examide&#39; STRING | required | | &#39;examide&#39; | . &#39;citoglipton&#39; STRING | required | | &#39;citoglipton&#39; | . &#39;insulin&#39; STRING | required | | &#39;insulin&#39; | . &#39;glyburide-metformin&#39; STRING | required | | &#39;glyburide-metformin&#39; | . &#39;glipizide-metformin&#39; STRING | required | | &#39;glipizide-metformin&#39; | . &#39;glimepiride-pioglitazone&#39; STRING | required | | &#39;glimepiride-pioglitazone&#39; | . &#39;metformin-rosiglitazone&#39; STRING | required | | &#39;metformin-rosiglitazone&#39; | . &#39;metformin-pioglitazone&#39; STRING | required | | &#39;metformin-pioglitazone&#39; | . &#39;change&#39; STRING | required | | &#39;change&#39; | . &#39;diabetesMed&#39; STRING | required | | &#39;diabetesMed&#39; | . &#39;readmitted&#39; STRING | required | | &#39;readmitted&#39; | . Values . Domain . &#39;race&#39; &#39;AfricanAmerican&#39;, &#39;Asian&#39;, &#39;Caucasian&#39;, &#39;Hispanic&#39;, &#39;Other&#39; | . &#39;gender&#39; &#39;Female&#39;, &#39;Male&#39;, &#39;Unknown/Invalid&#39; | . &#39;age&#39; &#39;[0-10)&#39;, &#39;[10-20)&#39;, &#39;[20-30)&#39;, &#39;[30-40)&#39;, &#39;[40-50)&#39;, &#39;[50-60)&#39;, &#39;[60-70)&#39;, &#39;[70-80)&#39;, &#39;[80-90)&#39;, &#39;[90-100)&#39; | . &#39;weight&#39; &#39;&gt;200&#39;, &#39;[0-25)&#39;, &#39;[100-125)&#39;, &#39;[125-150)&#39;, &#39;[150-175)&#39;, &#39;[175-200)&#39;, &#39;[25-50)&#39;, &#39;[50-75)&#39;, &#39;[75-100)&#39; | . &#39;payer_code&#39; &#39;BC&#39;, &#39;CH&#39;, &#39;CM&#39;, &#39;CP&#39;, &#39;DM&#39;, &#39;HM&#39;, &#39;MC&#39;, &#39;MD&#39;, &#39;MP&#39;, &#39;OG&#39;, &#39;OT&#39;, &#39;PO&#39;, &#39;SI&#39;, &#39;SP&#39;, &#39;UN&#39;, &#39;WC&#39; | . &#39;medical_specialty&#39; &#39;AllergyandImmunology&#39;, &#39;Anesthesiology&#39;, &#39;Anesthesiology-Pediatric&#39;, &#39;Cardiology&#39;, &#39;Cardiology-Pediatric&#39;, &#39;Dentistry&#39;, &#39;Dermatology&#39;, &#39;Emergency/Trauma&#39;, &#39;Endocrinology&#39;, &#39;Family/GeneralPractice&#39;, &#39;Gastroenterology&#39;, &#39;Gynecology&#39;, &#39;Hematology&#39;, &#39;Hematology/Oncology&#39;, &#39;Hospitalist&#39;, &#39;InfectiousDiseases&#39;, &#39;InternalMedicine&#39;, &#39;Nephrology&#39;, &#39;Neurology&#39;, &#39;Obsterics&amp;Gynecology-GynecologicOnco&#39;, &#39;Obstetrics&#39;, &#39;ObstetricsandGynecology&#39;, &#39;Oncology&#39;, &#39;Ophthalmology&#39;, &#39;Orthopedics&#39;, &#39;Orthopedics-Reconstructive&#39;, &#39;Osteopath&#39;, &#39;Otolaryngology&#39;, &#39;OutreachServices&#39;, &#39;Pathology&#39;, &#39;Pediatrics&#39;, &#39;Pediatrics-AllergyandImmunology&#39;, &#39;Pediatrics-CriticalCare&#39;, &#39;Pediatrics-EmergencyMedicine&#39;, &#39;Pediatrics-Endocrinology&#39;, &#39;Pediatrics-Hematology-Oncology&#39;, &#39;Pediatrics-InfectiousDiseases&#39;, &#39;Pediatrics-Neurology&#39;, &#39;Pediatrics-Pulmonology&#39;, &#39;Perinatology&#39;, &#39;PhysicalMedicineandRehabilitation&#39;, &#39;PhysicianNotFound&#39;, &#39;Podiatry&#39;, &#39;Proctology&#39;, &#39;Psychiatry&#39;, &#39;Psychiatry-Addictive&#39;, &#39;Psychiatry-Child/Adolescent&#39;, &#39;Psychology&#39;, &#39;Pulmonology&#39;, &#39;Radiologist&#39;, &#39;Radiology&#39;, &#39;Rheumatology&#39;, &#39;Speech&#39;, &#39;SportsMedicine&#39;, &#39;Surgeon&#39;, &#39;Surgery-Cardiovascular&#39;, &#39;Surgery-Cardiovascular/Thoracic&#39;, &#39;Surgery-Colon&amp;Rectal&#39;, &#39;Surgery-General&#39;, &#39;Surgery-Maxillofacial&#39;, &#39;Surgery-Neuro&#39;, &#39;Surgery-Pediatric&#39;, &#39;Surgery-Plastic&#39;, &#39;Surgery-PlasticwithinHeadandNeck&#39;, &#39;Surgery-Thoracic&#39;, &#39;Surgery-Vascular&#39;, &#39;SurgicalSpecialty&#39;, &#39;Urology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39; | . &#39;max_glu_serum&#39; &#39;&gt;200&#39;, &#39;&gt;300&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;A1Cresult&#39; &#39;&gt;7&#39;, &#39;&gt;8&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;repaglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;nateglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;chlorpropamide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glimepiride&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acetohexamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glipizide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;tolbutamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;pioglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;rosiglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acarbose&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;miglitol&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;troglitazone&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;tolazamide&#39; &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;examide&#39; &#39;No&#39; | . &#39;citoglipton&#39; &#39;No&#39; | . &#39;insulin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide-metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glipizide-metformin&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glimepiride-pioglitazone&#39; &#39;No&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39; | . &#39;metformin-rosiglitazone&#39; &#39;No&#39; | . &#39;metformin-pioglitazone&#39; &#39;No&#39; | . &#39;change&#39; &#39;Ch&#39;, &#39;No&#39; | . &#39;diabetesMed&#39; &#39;No&#39;, &#39;Yes&#39; | . &#39;readmitted&#39; &#39;&lt;30&#39;, &#39;&gt;30&#39;, &#39;NO&#39; | . Towards the bottom of the Domain-Values pairs of the cell above, you can see that many features (including &#39;metformin&#39;) have the same values: [&#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39;]. These values are common to many features including the ones with missing values during schema inference. . TFDV allows you to modify the domains of some features to match an existing domain. To address the detected anomaly, you can set the domain of these features to the domain of the metformin feature. . Complete the function below to set the domain of a feature list to an existing feature domain. . For this, use the tfdv.set_domain() function, which has the following parameters: . schema: The schema | . feature_path: The name of the feature whose domain needs to be set. | . domain: A domain protocol buffer or the name of a global string domain present in the input schema. | . def modify_domain_of_features(features_list, schema, to_domain_name): &#39;&#39;&#39; Modify a list of features&#39; domains. Parameters: features_list : Features that need to be modified schema: Inferred schema to_domain_name : Target domain to be transferred to the features list Returns: schema: new schema &#39;&#39;&#39; ### START CODE HERE # HINT: Loop over the feature list and use set_domain with the inferred schema, feature name and target domain name for feature in features_list: tfdv.set_domain(schema, feature, to_domain_name) ### END CODE HERE return schema . Using this function, set the domain of the features defined in the domain_change_features list below to be equal to metformin&#39;s domain to address the anomalies found. . Since you are overriding the existing domain of the features, it is normal to get a warning so you don&#39;t do this by accident. . domain_change_features = [&#39;repaglinide&#39;, &#39;nateglinide&#39;, &#39;chlorpropamide&#39;, &#39;glimepiride&#39;, &#39;acetohexamide&#39;, &#39;glipizide&#39;, &#39;glyburide&#39;, &#39;tolbutamide&#39;, &#39;pioglitazone&#39;, &#39;rosiglitazone&#39;, &#39;acarbose&#39;, &#39;miglitol&#39;, &#39;troglitazone&#39;, &#39;tolazamide&#39;, &#39;examide&#39;, &#39;citoglipton&#39;, &#39;insulin&#39;, &#39;glyburide-metformin&#39;, &#39;glipizide-metformin&#39;, &#39;glimepiride-pioglitazone&#39;, &#39;metformin-rosiglitazone&#39;, &#39;metformin-pioglitazone&#39;] # Infer new schema by using your modify_domain_of_features function # and the defined domain_change_features feature list schema = modify_domain_of_features(domain_change_features, schema, &#39;metformin&#39;) # Display new schema tfdv.display_schema(schema) . WARNING:root:Replacing existing domain of feature &#34;repaglinide&#34;. WARNING:root:Replacing existing domain of feature &#34;nateglinide&#34;. WARNING:root:Replacing existing domain of feature &#34;chlorpropamide&#34;. WARNING:root:Replacing existing domain of feature &#34;glimepiride&#34;. WARNING:root:Replacing existing domain of feature &#34;acetohexamide&#34;. WARNING:root:Replacing existing domain of feature &#34;glipizide&#34;. WARNING:root:Replacing existing domain of feature &#34;glyburide&#34;. WARNING:root:Replacing existing domain of feature &#34;tolbutamide&#34;. WARNING:root:Replacing existing domain of feature &#34;pioglitazone&#34;. WARNING:root:Replacing existing domain of feature &#34;rosiglitazone&#34;. WARNING:root:Replacing existing domain of feature &#34;acarbose&#34;. WARNING:root:Replacing existing domain of feature &#34;miglitol&#34;. WARNING:root:Replacing existing domain of feature &#34;troglitazone&#34;. WARNING:root:Replacing existing domain of feature &#34;tolazamide&#34;. WARNING:root:Replacing existing domain of feature &#34;examide&#34;. WARNING:root:Replacing existing domain of feature &#34;citoglipton&#34;. WARNING:root:Replacing existing domain of feature &#34;insulin&#34;. WARNING:root:Replacing existing domain of feature &#34;glyburide-metformin&#34;. WARNING:root:Replacing existing domain of feature &#34;glipizide-metformin&#34;. WARNING:root:Replacing existing domain of feature &#34;glimepiride-pioglitazone&#34;. WARNING:root:Replacing existing domain of feature &#34;metformin-rosiglitazone&#34;. WARNING:root:Replacing existing domain of feature &#34;metformin-pioglitazone&#34;. . Type Presence Valency Domain . Feature name . &#39;race&#39; STRING | optional | single | &#39;race&#39; | . &#39;gender&#39; STRING | required | | &#39;gender&#39; | . &#39;age&#39; STRING | required | | &#39;age&#39; | . &#39;weight&#39; STRING | optional | single | &#39;weight&#39; | . &#39;admission_type_id&#39; INT | required | | - | . &#39;discharge_disposition_id&#39; INT | required | | - | . &#39;admission_source_id&#39; INT | required | | - | . &#39;time_in_hospital&#39; INT | required | | - | . &#39;payer_code&#39; STRING | optional | single | &#39;payer_code&#39; | . &#39;medical_specialty&#39; STRING | optional | single | &#39;medical_specialty&#39; | . &#39;num_lab_procedures&#39; INT | required | | - | . &#39;num_procedures&#39; INT | required | | - | . &#39;num_medications&#39; INT | required | | - | . &#39;number_outpatient&#39; INT | required | | - | . &#39;number_emergency&#39; INT | required | | - | . &#39;number_inpatient&#39; INT | required | | - | . &#39;diag_1&#39; BYTES | optional | single | - | . &#39;diag_2&#39; BYTES | optional | single | - | . &#39;diag_3&#39; BYTES | optional | single | - | . &#39;number_diagnoses&#39; INT | required | | - | . &#39;max_glu_serum&#39; STRING | required | | &#39;max_glu_serum&#39; | . &#39;A1Cresult&#39; STRING | required | | &#39;A1Cresult&#39; | . &#39;metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;repaglinide&#39; STRING | required | | &#39;metformin&#39; | . &#39;nateglinide&#39; STRING | required | | &#39;metformin&#39; | . &#39;chlorpropamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;glimepiride&#39; STRING | required | | &#39;metformin&#39; | . &#39;acetohexamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;glipizide&#39; STRING | required | | &#39;metformin&#39; | . &#39;glyburide&#39; STRING | required | | &#39;metformin&#39; | . &#39;tolbutamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;pioglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;rosiglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;acarbose&#39; STRING | required | | &#39;metformin&#39; | . &#39;miglitol&#39; STRING | required | | &#39;metformin&#39; | . &#39;troglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;tolazamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;examide&#39; STRING | required | | &#39;metformin&#39; | . &#39;citoglipton&#39; STRING | required | | &#39;metformin&#39; | . &#39;insulin&#39; STRING | required | | &#39;metformin&#39; | . &#39;glyburide-metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;glipizide-metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;glimepiride-pioglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;metformin-rosiglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;metformin-pioglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;change&#39; STRING | required | | &#39;change&#39; | . &#39;diabetesMed&#39; STRING | required | | &#39;diabetesMed&#39; | . &#39;readmitted&#39; STRING | required | | &#39;readmitted&#39; | . Values . Domain . &#39;race&#39; &#39;AfricanAmerican&#39;, &#39;Asian&#39;, &#39;Caucasian&#39;, &#39;Hispanic&#39;, &#39;Other&#39; | . &#39;gender&#39; &#39;Female&#39;, &#39;Male&#39;, &#39;Unknown/Invalid&#39; | . &#39;age&#39; &#39;[0-10)&#39;, &#39;[10-20)&#39;, &#39;[20-30)&#39;, &#39;[30-40)&#39;, &#39;[40-50)&#39;, &#39;[50-60)&#39;, &#39;[60-70)&#39;, &#39;[70-80)&#39;, &#39;[80-90)&#39;, &#39;[90-100)&#39; | . &#39;weight&#39; &#39;&gt;200&#39;, &#39;[0-25)&#39;, &#39;[100-125)&#39;, &#39;[125-150)&#39;, &#39;[150-175)&#39;, &#39;[175-200)&#39;, &#39;[25-50)&#39;, &#39;[50-75)&#39;, &#39;[75-100)&#39; | . &#39;payer_code&#39; &#39;BC&#39;, &#39;CH&#39;, &#39;CM&#39;, &#39;CP&#39;, &#39;DM&#39;, &#39;HM&#39;, &#39;MC&#39;, &#39;MD&#39;, &#39;MP&#39;, &#39;OG&#39;, &#39;OT&#39;, &#39;PO&#39;, &#39;SI&#39;, &#39;SP&#39;, &#39;UN&#39;, &#39;WC&#39; | . &#39;medical_specialty&#39; &#39;AllergyandImmunology&#39;, &#39;Anesthesiology&#39;, &#39;Anesthesiology-Pediatric&#39;, &#39;Cardiology&#39;, &#39;Cardiology-Pediatric&#39;, &#39;Dentistry&#39;, &#39;Dermatology&#39;, &#39;Emergency/Trauma&#39;, &#39;Endocrinology&#39;, &#39;Family/GeneralPractice&#39;, &#39;Gastroenterology&#39;, &#39;Gynecology&#39;, &#39;Hematology&#39;, &#39;Hematology/Oncology&#39;, &#39;Hospitalist&#39;, &#39;InfectiousDiseases&#39;, &#39;InternalMedicine&#39;, &#39;Nephrology&#39;, &#39;Neurology&#39;, &#39;Obsterics&amp;Gynecology-GynecologicOnco&#39;, &#39;Obstetrics&#39;, &#39;ObstetricsandGynecology&#39;, &#39;Oncology&#39;, &#39;Ophthalmology&#39;, &#39;Orthopedics&#39;, &#39;Orthopedics-Reconstructive&#39;, &#39;Osteopath&#39;, &#39;Otolaryngology&#39;, &#39;OutreachServices&#39;, &#39;Pathology&#39;, &#39;Pediatrics&#39;, &#39;Pediatrics-AllergyandImmunology&#39;, &#39;Pediatrics-CriticalCare&#39;, &#39;Pediatrics-EmergencyMedicine&#39;, &#39;Pediatrics-Endocrinology&#39;, &#39;Pediatrics-Hematology-Oncology&#39;, &#39;Pediatrics-InfectiousDiseases&#39;, &#39;Pediatrics-Neurology&#39;, &#39;Pediatrics-Pulmonology&#39;, &#39;Perinatology&#39;, &#39;PhysicalMedicineandRehabilitation&#39;, &#39;PhysicianNotFound&#39;, &#39;Podiatry&#39;, &#39;Proctology&#39;, &#39;Psychiatry&#39;, &#39;Psychiatry-Addictive&#39;, &#39;Psychiatry-Child/Adolescent&#39;, &#39;Psychology&#39;, &#39;Pulmonology&#39;, &#39;Radiologist&#39;, &#39;Radiology&#39;, &#39;Rheumatology&#39;, &#39;Speech&#39;, &#39;SportsMedicine&#39;, &#39;Surgeon&#39;, &#39;Surgery-Cardiovascular&#39;, &#39;Surgery-Cardiovascular/Thoracic&#39;, &#39;Surgery-Colon&amp;Rectal&#39;, &#39;Surgery-General&#39;, &#39;Surgery-Maxillofacial&#39;, &#39;Surgery-Neuro&#39;, &#39;Surgery-Pediatric&#39;, &#39;Surgery-Plastic&#39;, &#39;Surgery-PlasticwithinHeadandNeck&#39;, &#39;Surgery-Thoracic&#39;, &#39;Surgery-Vascular&#39;, &#39;SurgicalSpecialty&#39;, &#39;Urology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39; | . &#39;max_glu_serum&#39; &#39;&gt;200&#39;, &#39;&gt;300&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;A1Cresult&#39; &#39;&gt;7&#39;, &#39;&gt;8&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;repaglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;nateglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;chlorpropamide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glimepiride&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acetohexamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glipizide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;tolbutamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;pioglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;rosiglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acarbose&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;miglitol&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;troglitazone&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;tolazamide&#39; &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;examide&#39; &#39;No&#39; | . &#39;citoglipton&#39; &#39;No&#39; | . &#39;insulin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide-metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glipizide-metformin&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glimepiride-pioglitazone&#39; &#39;No&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39; | . &#39;metformin-rosiglitazone&#39; &#39;No&#39; | . &#39;metformin-pioglitazone&#39; &#39;No&#39; | . &#39;change&#39; &#39;Ch&#39;, &#39;No&#39; | . &#39;diabetesMed&#39; &#39;No&#39;, &#39;Yes&#39; | . &#39;readmitted&#39; &#39;&lt;30&#39;, &#39;&gt;30&#39;, &#39;NO&#39; | . # check that the domain of some features are now switched to `metformin` print(f&quot;Domain name of &#39;chlorpropamide&#39;: {tfdv.get_feature(schema, &#39;chlorpropamide&#39;).domain}&quot;) print(f&quot;Domain values of &#39;chlorpropamide&#39;: {tfdv.get_domain(schema, &#39;chlorpropamide&#39;).value}&quot;) print(f&quot;Domain name of &#39;repaglinide&#39;: {tfdv.get_feature(schema, &#39;repaglinide&#39;).domain}&quot;) print(f&quot;Domain values of &#39;repaglinide&#39;: {tfdv.get_domain(schema, &#39;repaglinide&#39;).value}&quot;) print(f&quot;Domain name of &#39;nateglinide&#39;: {tfdv.get_feature(schema, &#39;nateglinide&#39;).domain}&quot;) print(f&quot;Domain values of &#39;nateglinide&#39;: {tfdv.get_domain(schema, &#39;nateglinide&#39;).value}&quot;) . Domain name of &#39;chlorpropamide&#39;: metformin Domain values of &#39;chlorpropamide&#39;: [&#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39;] Domain name of &#39;repaglinide&#39;: metformin Domain values of &#39;repaglinide&#39;: [&#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39;] Domain name of &#39;nateglinide&#39;: metformin Domain values of &#39;nateglinide&#39;: [&#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39;] . Expected Output: . Domain name of &#39;chlorpropamide&#39;: metformin Domain values of &#39;chlorpropamide&#39;: [&#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39;] Domain name of &#39;repaglinide&#39;: metformin Domain values of &#39;repaglinide&#39;: [&#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39;] Domain name of &#39;nateglinide&#39;: metformin Domain values of &#39;nateglinide&#39;: [&#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39;] . Let&#39;s do a final check of anomalies to see if this solved the issue. . calculate_and_display_anomalies(serving_stats, schema=schema) . Anomaly short description Anomaly long description . Feature name . &#39;readmitted&#39; Column dropped | Column is completely missing | . You should now see the metformin-pioglitazone and metformin-rosiglitazone features dropped from the output anomalies. . . Exercise 9: Detecting anomalies with environments . There is still one thing to address. The readmitted feature (which is the label column) showed up as an anomaly (&#39;Column dropped&#39;). Since labels are not expected in the serving data, let&#39;s tell TFDV to ignore this detected anomaly. . This requirement of introducing slight schema variations can be expressed by using environments. In particular, features in the schema can be associated with a set of environments using default_environment, in_environment and not_in_environment. . schema.default_environment.append(&#39;TRAINING&#39;) schema.default_environment.append(&#39;SERVING&#39;) tfdv.display_schema(schema) . Type Presence Valency Domain . Feature name . &#39;race&#39; STRING | optional | single | &#39;race&#39; | . &#39;gender&#39; STRING | required | | &#39;gender&#39; | . &#39;age&#39; STRING | required | | &#39;age&#39; | . &#39;weight&#39; STRING | optional | single | &#39;weight&#39; | . &#39;admission_type_id&#39; INT | required | | - | . &#39;discharge_disposition_id&#39; INT | required | | - | . &#39;admission_source_id&#39; INT | required | | - | . &#39;time_in_hospital&#39; INT | required | | - | . &#39;payer_code&#39; STRING | optional | single | &#39;payer_code&#39; | . &#39;medical_specialty&#39; STRING | optional | single | &#39;medical_specialty&#39; | . &#39;num_lab_procedures&#39; INT | required | | - | . &#39;num_procedures&#39; INT | required | | - | . &#39;num_medications&#39; INT | required | | - | . &#39;number_outpatient&#39; INT | required | | - | . &#39;number_emergency&#39; INT | required | | - | . &#39;number_inpatient&#39; INT | required | | - | . &#39;diag_1&#39; BYTES | optional | single | - | . &#39;diag_2&#39; BYTES | optional | single | - | . &#39;diag_3&#39; BYTES | optional | single | - | . &#39;number_diagnoses&#39; INT | required | | - | . &#39;max_glu_serum&#39; STRING | required | | &#39;max_glu_serum&#39; | . &#39;A1Cresult&#39; STRING | required | | &#39;A1Cresult&#39; | . &#39;metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;repaglinide&#39; STRING | required | | &#39;metformin&#39; | . &#39;nateglinide&#39; STRING | required | | &#39;metformin&#39; | . &#39;chlorpropamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;glimepiride&#39; STRING | required | | &#39;metformin&#39; | . &#39;acetohexamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;glipizide&#39; STRING | required | | &#39;metformin&#39; | . &#39;glyburide&#39; STRING | required | | &#39;metformin&#39; | . &#39;tolbutamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;pioglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;rosiglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;acarbose&#39; STRING | required | | &#39;metformin&#39; | . &#39;miglitol&#39; STRING | required | | &#39;metformin&#39; | . &#39;troglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;tolazamide&#39; STRING | required | | &#39;metformin&#39; | . &#39;examide&#39; STRING | required | | &#39;metformin&#39; | . &#39;citoglipton&#39; STRING | required | | &#39;metformin&#39; | . &#39;insulin&#39; STRING | required | | &#39;metformin&#39; | . &#39;glyburide-metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;glipizide-metformin&#39; STRING | required | | &#39;metformin&#39; | . &#39;glimepiride-pioglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;metformin-rosiglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;metformin-pioglitazone&#39; STRING | required | | &#39;metformin&#39; | . &#39;change&#39; STRING | required | | &#39;change&#39; | . &#39;diabetesMed&#39; STRING | required | | &#39;diabetesMed&#39; | . &#39;readmitted&#39; STRING | required | | &#39;readmitted&#39; | . Values . Domain . &#39;race&#39; &#39;AfricanAmerican&#39;, &#39;Asian&#39;, &#39;Caucasian&#39;, &#39;Hispanic&#39;, &#39;Other&#39; | . &#39;gender&#39; &#39;Female&#39;, &#39;Male&#39;, &#39;Unknown/Invalid&#39; | . &#39;age&#39; &#39;[0-10)&#39;, &#39;[10-20)&#39;, &#39;[20-30)&#39;, &#39;[30-40)&#39;, &#39;[40-50)&#39;, &#39;[50-60)&#39;, &#39;[60-70)&#39;, &#39;[70-80)&#39;, &#39;[80-90)&#39;, &#39;[90-100)&#39; | . &#39;weight&#39; &#39;&gt;200&#39;, &#39;[0-25)&#39;, &#39;[100-125)&#39;, &#39;[125-150)&#39;, &#39;[150-175)&#39;, &#39;[175-200)&#39;, &#39;[25-50)&#39;, &#39;[50-75)&#39;, &#39;[75-100)&#39; | . &#39;payer_code&#39; &#39;BC&#39;, &#39;CH&#39;, &#39;CM&#39;, &#39;CP&#39;, &#39;DM&#39;, &#39;HM&#39;, &#39;MC&#39;, &#39;MD&#39;, &#39;MP&#39;, &#39;OG&#39;, &#39;OT&#39;, &#39;PO&#39;, &#39;SI&#39;, &#39;SP&#39;, &#39;UN&#39;, &#39;WC&#39; | . &#39;medical_specialty&#39; &#39;AllergyandImmunology&#39;, &#39;Anesthesiology&#39;, &#39;Anesthesiology-Pediatric&#39;, &#39;Cardiology&#39;, &#39;Cardiology-Pediatric&#39;, &#39;Dentistry&#39;, &#39;Dermatology&#39;, &#39;Emergency/Trauma&#39;, &#39;Endocrinology&#39;, &#39;Family/GeneralPractice&#39;, &#39;Gastroenterology&#39;, &#39;Gynecology&#39;, &#39;Hematology&#39;, &#39;Hematology/Oncology&#39;, &#39;Hospitalist&#39;, &#39;InfectiousDiseases&#39;, &#39;InternalMedicine&#39;, &#39;Nephrology&#39;, &#39;Neurology&#39;, &#39;Obsterics&amp;Gynecology-GynecologicOnco&#39;, &#39;Obstetrics&#39;, &#39;ObstetricsandGynecology&#39;, &#39;Oncology&#39;, &#39;Ophthalmology&#39;, &#39;Orthopedics&#39;, &#39;Orthopedics-Reconstructive&#39;, &#39;Osteopath&#39;, &#39;Otolaryngology&#39;, &#39;OutreachServices&#39;, &#39;Pathology&#39;, &#39;Pediatrics&#39;, &#39;Pediatrics-AllergyandImmunology&#39;, &#39;Pediatrics-CriticalCare&#39;, &#39;Pediatrics-EmergencyMedicine&#39;, &#39;Pediatrics-Endocrinology&#39;, &#39;Pediatrics-Hematology-Oncology&#39;, &#39;Pediatrics-InfectiousDiseases&#39;, &#39;Pediatrics-Neurology&#39;, &#39;Pediatrics-Pulmonology&#39;, &#39;Perinatology&#39;, &#39;PhysicalMedicineandRehabilitation&#39;, &#39;PhysicianNotFound&#39;, &#39;Podiatry&#39;, &#39;Proctology&#39;, &#39;Psychiatry&#39;, &#39;Psychiatry-Addictive&#39;, &#39;Psychiatry-Child/Adolescent&#39;, &#39;Psychology&#39;, &#39;Pulmonology&#39;, &#39;Radiologist&#39;, &#39;Radiology&#39;, &#39;Rheumatology&#39;, &#39;Speech&#39;, &#39;SportsMedicine&#39;, &#39;Surgeon&#39;, &#39;Surgery-Cardiovascular&#39;, &#39;Surgery-Cardiovascular/Thoracic&#39;, &#39;Surgery-Colon&amp;Rectal&#39;, &#39;Surgery-General&#39;, &#39;Surgery-Maxillofacial&#39;, &#39;Surgery-Neuro&#39;, &#39;Surgery-Pediatric&#39;, &#39;Surgery-Plastic&#39;, &#39;Surgery-PlasticwithinHeadandNeck&#39;, &#39;Surgery-Thoracic&#39;, &#39;Surgery-Vascular&#39;, &#39;SurgicalSpecialty&#39;, &#39;Urology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39;, &#39;Neurophysiology&#39; | . &#39;max_glu_serum&#39; &#39;&gt;200&#39;, &#39;&gt;300&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;A1Cresult&#39; &#39;&gt;7&#39;, &#39;&gt;8&#39;, &#39;None&#39;, &#39;Norm&#39; | . &#39;metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;repaglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;nateglinide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;chlorpropamide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glimepiride&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acetohexamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glipizide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;tolbutamide&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;pioglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;rosiglitazone&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;acarbose&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;miglitol&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;troglitazone&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;tolazamide&#39; &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;examide&#39; &#39;No&#39; | . &#39;citoglipton&#39; &#39;No&#39; | . &#39;insulin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glyburide-metformin&#39; &#39;Down&#39;, &#39;No&#39;, &#39;Steady&#39;, &#39;Up&#39; | . &#39;glipizide-metformin&#39; &#39;No&#39;, &#39;Steady&#39; | . &#39;glimepiride-pioglitazone&#39; &#39;No&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39;, &#39;Steady&#39; | . &#39;metformin-rosiglitazone&#39; &#39;No&#39; | . &#39;metformin-pioglitazone&#39; &#39;No&#39; | . &#39;change&#39; &#39;Ch&#39;, &#39;No&#39; | . &#39;diabetesMed&#39; &#39;No&#39;, &#39;Yes&#39; | . &#39;readmitted&#39; &#39;&lt;30&#39;, &#39;&gt;30&#39;, &#39;NO&#39; | . Complete the code below to exclude the readmitted feature from the SERVING environment. . To achieve this, you can use the tfdv.get_feature() function to get the readmitted feature from the inferred schema and use its not_in_environment attribute to specify that readmitted should be removed from the SERVING environment&#39;s schema. This attribute is a list so you will have to append the name of the environment that you wish to omit this feature for. . To be more explicit, given a feature you can do something like: . feature.not_in_environment.append(&#39;NAME_OF_ENVIRONMENT&#39;) . The function tfdv.get_feature receives the following parameters: . schema: The schema. | feature_path: The path of the feature to obtain from the schema. In this case this is equal to the name of the feature. | . # Specify that &#39;readmitted&#39; feature is not in SERVING environment. # HINT: Append the &#39;SERVING&#39; environmnet to the not_in_environment attribute of the feature #tfdv.get_feature(schema, None).not_in_environment.append(None) not_in_environment_feature = tfdv.get_feature(schema,&#39;readmitted&#39;).not_in_environment.append(&#39;SERVING&#39;) # HINT: Calculate anomalies with the validate_statistics function by using the serving statistics, # inferred schema and the SERVING environment parameter. #serving_anomalies_with_env = tfdv.validate_statistics(None, schema, environment=None) serving_anomalies_with_env = tfdv.validate_statistics(serving_stats, schema, environment=not_in_environment_feature) ### END CODE HERE . You should see &quot;No anomalies found&quot; by running the cell below. . tfdv.display_anomalies(serving_anomalies_with_env) . Anomaly short description Anomaly long description . Feature name . &#39;readmitted&#39; Column dropped | Column is completely missing | . Now you have succesfully addressed all anomaly-related issues! . . 7 - Check for Data Drift and Skew . During data validation, you also need to check for data drift and data skew between the training and serving data. You can do this by specifying the skew_comparator and drift_comparator in the schema. . Drift and skew is expressed in terms of L-infinity distance which evaluates the difference between vectors as the greatest of the differences along any coordinate dimension. . You can set the threshold distance so that you receive warnings when the drift is higher than is acceptable. Setting the correct distance is typically an iterative process requiring domain knowledge and experimentation. . Let&#39;s check for the skew in the diabetesMed feature and drift in the payer_code feature. . diabetes_med = tfdv.get_feature(schema, &#39;diabetesMed&#39;) diabetes_med.skew_comparator.infinity_norm.threshold = 0.035 # domain knowledge helps to determine this threshold # Calculate drift for the payer_code feature payer_code = tfdv.get_feature(schema, &#39;payer_code&#39;) payer_code.drift_comparator.infinity_norm.threshold = 0.035 # domain knowledge helps to determine this threshold # Calculate anomalies skew_drift_anomalies = tfdv.validate_statistics(train_stats, schema, previous_statistics=eval_stats, serving_statistics=serving_stats) # Display anomalies tfdv.display_anomalies(skew_drift_anomalies) . No anomalies found. . In both of these cases, the detected anomaly distance is not too far from the threshold value of 0.03. For this exercise, let&#39;s accept this as within bounds (i.e. you can set the distance to something like 0.035 instead). . However, if the anomaly truly indicates a skew and drift, then further investigation is necessary as this could have a direct impact on model performance. . . 8 - Display Stats for Data Slices . Finally, you can slice the dataset and calculate the statistics for each unique value of a feature. By default, TFDV computes statistics for the overall dataset in addition to the configured slices. Each slice is identified by a unique name which is set as the dataset name in the DatasetFeatureStatistics protocol buffer. Generating and displaying statistics over different slices of data can help track model and anomaly metrics. . Let&#39;s first define a few helper functions to make our code in the exercise more neat. . def split_datasets(dataset_list): &#39;&#39;&#39; split datasets. Parameters: dataset_list: List of datasets to split Returns: datasets: sliced data &#39;&#39;&#39; datasets = [] for dataset in dataset_list.datasets: proto_list = DatasetFeatureStatisticsList() proto_list.datasets.extend([dataset]) datasets.append(proto_list) return datasets def display_stats_at_index(index, datasets): &#39;&#39;&#39; display statistics at the specified data index Parameters: index : index to show the anomalies datasets: split data Returns: display of generated sliced data statistics at the specified index &#39;&#39;&#39; if index &lt; len(datasets): print(datasets[index].datasets[0].name) tfdv.visualize_statistics(datasets[index]) . The function below returns a list of DatasetFeatureStatisticsList protocol buffers. As shown in the ungraded lab, the first one will be for All Examples followed by individual slices through the feature you specified. . To configure TFDV to generate statistics for dataset slices, you will use the function tfdv.StatsOptions() with the following 4 arguments: . schema | . slice_functions passed as a list. | . infer_type_from_schema set to True. | . feature_whitelist set to the approved features. | . Remember that slice_functions only work with generate_statistics_from_csv() so you will need to convert the dataframe to CSV. . def sliced_stats_for_slice_fn(slice_fn, approved_cols, dataframe, schema): &#39;&#39;&#39; generate statistics for the sliced data. Parameters: slice_fn : slicing definition approved_cols: list of features to pass to the statistics options dataframe: pandas dataframe to slice schema: the schema Returns: slice_info_datasets: statistics for the sliced dataset &#39;&#39;&#39; # Set the StatsOptions slice_stats_options = tfdv.StatsOptions(schema=schema, slice_functions=[slice_fn], infer_type_from_schema=True, feature_whitelist=approved_cols) # Convert Dataframe to CSV since `slice_functions` works only with `tfdv.generate_statistics_from_csv` CSV_PATH = &#39;slice_sample.csv&#39; dataframe.to_csv(CSV_PATH) # Calculate statistics for the sliced dataset sliced_stats = tfdv.generate_statistics_from_csv(CSV_PATH, stats_options=slice_stats_options) # Split the dataset using the previously defined split_datasets function slice_info_datasets = split_datasets(sliced_stats) return slice_info_datasets . With that, you can now use the helper functions to generate and visualize statistics for the sliced datasets. . slice_fn = slicing_util.get_feature_value_slicer(features={&#39;medical_specialty&#39;: None}) # Generate stats for the sliced dataset slice_datasets = sliced_stats_for_slice_fn(slice_fn, approved_cols, dataframe=train_df, schema=schema) # Print name of slices for reference print(f&#39;Statistics generated for: n&#39;) print(&#39; n&#39;.join([sliced.datasets[0].name for sliced in slice_datasets])) # Display at index 10, which corresponds to the slice named `medical_specialty_Gastroenterology` display_stats_at_index(1, slice_datasets) . Statistics generated for: All Examples medical_specialty_Orthopedics medical_specialty_InternalMedicine medical_specialty_Cardiology medical_specialty_Family/GeneralPractice medical_specialty_Surgery-General medical_specialty_Emergency/Trauma medical_specialty_Nephrology medical_specialty_Surgery-Neuro medical_specialty_Oncology medical_specialty_Gastroenterology medical_specialty_Orthopedics-Reconstructive medical_specialty_ObstetricsandGynecology medical_specialty_Surgery-Cardiovascular/Thoracic medical_specialty_Radiologist medical_specialty_Urology medical_specialty_Surgery-Vascular medical_specialty_Hematology/Oncology medical_specialty_Neurology medical_specialty_Psychology medical_specialty_Psychiatry medical_specialty_PhysicalMedicineandRehabilitation medical_specialty_Pulmonology medical_specialty_Otolaryngology medical_specialty_Obsterics&amp;Gynecology-GynecologicOnco medical_specialty_Endocrinology medical_specialty_Anesthesiology medical_specialty_Pediatrics-Endocrinology medical_specialty_Radiology medical_specialty_Pediatrics medical_specialty_Pediatrics-Pulmonology medical_specialty_Osteopath medical_specialty_Surgery-Plastic medical_specialty_Podiatry medical_specialty_Surgery-Thoracic medical_specialty_Rheumatology medical_specialty_Obstetrics medical_specialty_Pediatrics-AllergyandImmunology medical_specialty_Surgery-Cardiovascular medical_specialty_Anesthesiology-Pediatric medical_specialty_Pathology medical_specialty_Pediatrics-CriticalCare medical_specialty_PhysicianNotFound medical_specialty_Gynecology medical_specialty_AllergyandImmunology medical_specialty_Surgery-Maxillofacial medical_specialty_Hospitalist medical_specialty_Hematology medical_specialty_Surgeon medical_specialty_Proctology medical_specialty_InfectiousDiseases medical_specialty_Psychiatry-Child/Adolescent medical_specialty_SurgicalSpecialty medical_specialty_Ophthalmology medical_specialty_Surgery-Pediatric medical_specialty_Pediatrics-Neurology medical_specialty_Surgery-PlasticwithinHeadandNeck medical_specialty_OutreachServices medical_specialty_Pediatrics-Hematology-Oncology medical_specialty_Dentistry medical_specialty_Pediatrics-EmergencyMedicine medical_specialty_Psychiatry-Addictive medical_specialty_Surgery-Colon&amp;Rectal medical_specialty_Pediatrics-InfectiousDiseases medical_specialty_Dermatology medical_specialty_Perinatology medical_specialty_SportsMedicine medical_specialty_Cardiology-Pediatric medical_specialty_Speech medical_specialty_Orthopedics . If you are curious, try different slice indices to extract the group statistics. For instance, index=5 corresponds to all medical_specialty_Surgery-General records. You can also try slicing through multiple features as shown in the ungraded lab. . Another challenge is to implement your own helper functions. For instance, you can make a display_stats_for_slice_name() function so you don&#39;t have to determine the index of a slice. If done correctly, you can just do display_stats_for_slice_name(&#39;medical_specialty_Gastroenterology&#39;, slice_datasets) and it will generate the same result as display_stats_at_index(10, slice_datasets). . . 9 - Freeze the schema . Now that the schema has been reviewed, you will store the schema in a file in its &quot;frozen&quot; state. This can be used to validate incoming data once your application goes live to your users. . This is pretty straightforward using Tensorflow&#39;s io utils and TFDV&#39;s write_schema_text() function. . OUTPUT_DIR = &quot;output&quot; file_io.recursive_create_dir(OUTPUT_DIR) # Use TensorFlow text output format pbtxt to store the schema schema_file = os.path.join(OUTPUT_DIR, &#39;schema.pbtxt&#39;) # write_schema_text function expect the defined schema and output path as parameters tfdv.write_schema_text(schema, schema_file) . After submitting this assignment, you can click the Jupyter logo in the left upper corner of the screen to check the Jupyter filesystem. The schema.pbtxt file should be inside the output directory. . Congratulations on finishing this week&#39;s assignment! A lot of concepts where introduced and now you should feel more familiar with using TFDV for inferring schemas, anomaly detection and other data-related tasks. . Keep it up! .",
            "url": "https://marcelcastrobr.github.io/notebooks/jupyter/tensorflow/2021/09/04/FeatureEngTensorflow.html",
            "relUrl": "/jupyter/tensorflow/2021/09/04/FeatureEngTensorflow.html",
            "date": " • Sep 4, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://marcelcastrobr.github.io/notebooks/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://marcelcastrobr.github.io/notebooks/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://marcelcastrobr.github.io/notebooks/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://marcelcastrobr.github.io/notebooks/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}